\section{Background}\label{sect:background}
\subsection{DeepFakes}\label{subsect:deepfakes}
In late 2017, \gls{redditor} \textit{deepfake} began publishing pornographic footage
on \url{https://www.reddit.com/r/deepfakes}, where he replaced the actors' faces,
with those of celebrities, without their consent. As a consequence, he
received increased media coverage in early 2018, after the release of a first 
article and interview on vice-motherboard~\cite{Cole.2017}. While he coined the
term \textit{DeepFake} for face-\textit{replacement} and face-\textit{reenactment}
technologies, both were already actively researched in academia with research 
dating back to at least 1997~\cite{Bregler.1997}.

\subsubsection{DeepFakes and CheapFakes}
In this work, a further distinction between the so called CheapFakes and \textit{DeepFakes}
is made. On the one hand, CheapFakes are produced by using contemporary video- 
and picture editing software. The name CheapFake should under no circumstance be
interpreted as an assessment of their effectiveness since they can still be used
to effectively fool users. An example of this usage might be a video of US House
Speaker Nancy Pelosi which was slowed down for her to appear drunk\todo{add reference}.
On the other hand, \textit{DeepFakes} describe the results of machine-learning
algorithms, which are most often a form of or combination of \glspl{nn}.
The names simply refer to the different levels of sophistication of the different
approaches. Arguably, at some point, they might even merge together with editing 
software utilizing machine learning more and \textit{DeepFake} technology becoming
accessible and integrated into existing tooling.

\subsubsection{Flavors of DeepFakes}\label{subsubsect:deepfake-flavors}
Face swap, face replacement, face reenactment, body reenactment\todo{write falvors of deepfakes}


\subsubsection{Generalizability of Generative Models for DeepFakes}\label{subsubsect:generalizability-deepfakes}
In the design of \glspl{nn} for the creation of \textit{DeepFakes}, one must choose the
targets to which it is applicable~\cite[cf.][]{Mirsky.2020}:
\begin{description}
    \item[one-to-one] after training, the approach is applicable only to a
    single target and driver
    \item[many-to-one] after training, the approach is applicable only to a
    single target, but arbitrary drivers
    \item[many-to-many] after training, the approach is applicable both to
    arbitrary targets and drivers
\end{description}
As mentioned in \cref{subsect:limitations}, only \textbf{many-to-many} approaches
are presented because they are more generic than \textbf{one-to-one} or
\textbf{many-to-one}.

\subsection{Ethical Challenges}
The importance of \textit{DeepFake}-Detection increases together with the ethical
challenges which arise from the use of this technology. The ability to create
arbitrary fake images bears multiple risks for misuse: Firstly, there is the
aspect of misinformation and propaganda. For example, showing images or videos
of political candidates saying things they have not said can incriminate
them. Moreover, another aspect to take into consideration would be pornography,
since it is possible to change faces to other peopleÂ´s bodies, which can lead to
non-consensual pornography. Following these two dimensions, there are two groups
at risk: public or political figures and private individuals. The first category
is defined by attackers having more resources at hand for an attack, e.g.\ an
organized action against a specific political candidate. The second category in 
contrast is defined by attackers not having that many resources, e.g.\ an angry 
ex-boyfriend. Even though the second category might be of great risk, since not 
that much might be needed to spread a basic amount of false information, in the 
end their capabilities are somewhat limited. Changes in the ease of use and 
availability of \textit{DeepFake} technologies would mostly affect the second category, 
since the first already has the necessary resources in the first place. Depending 
on this ease of use, most attackers might be expected to fall into the second 
category. These might not use the best technology which potentially makes them 
susceptible for \textit{DeepFake} detection methods. In this respect the \textit{DeepFakes}
created for the first category might pose more of a challenge.
 