\section{Background}\label{sect:background}

\subsection{DeepFakes and CheapFakes}
In this work, a distinction between so called CheapFakes and \textit{DeepFakes}
is made. On the one hand, CheapFakes are produced by using contemporary video 
and picture editing software. The name CheapFake should under no circumstance be
interpreted as an assessment of their effectiveness since they can still be used
to effectively fool users. An example of this usage might be a video of US House
Speaker Nancy Pelosi which was slowed down for her to appear drunk~\cite{Fichera.2019}.
On the other hand, \textit{DeepFakes} describe the results of machine-learning
algorithms, which are most often a form of or combination of \glspl{nn}.
The names simply refer to the different levels of sophistication of the different
approaches. Arguably, at some point, they might even merge together with editing 
software utilizing machine learning more and \textit{DeepFake} technology becoming
accessible and integrated into existing tooling.

\subsection{Flavors of DeepFakes}\label{subsubsect:deepfake-flavors}
Broadly, \textit{DeepFakes} can be sorted into two categories, as described by~\textcite{Mirsky.2020}:
There is a source \textit{s} and a target \textit{t}

\begin{description}
    \item[Face Reenacment] Here, the expression of \textit{s} is used to drive
    the expression of \textit{t}~\cite{Mirsky.2020}. The source is
    therefore also called driver \textit{d}.
    \item[Replacement] In this case, some part of \textit{t} is replaced
    by the corresponding part of \textit{s}. An example would be the swapping of
    \textit{t}'s face with the one from \textit{s}, preserving \textit{t}'s mimic.
\end{description}

\subsection{Generalizability of Generative Models for DeepFakes}\label{subsubsect:generalizability-deepfakes}
In the design of \glspl{nn} for the creation of \textit{DeepFakes}, one must choose
the range of targets to which it is applicable~\cite[cf.][]{Mirsky.2020}:
\begin{description}
    \item[one-to-one] after training, the approach is applicable only to a
    single target and source/driver;
    \item[many-to-one] after training, the approach is applicable only to a
    single target, but arbitrary sources/drivers;
    \item[many-to-many] after training, the approach is applicable both to
    arbitrary targets and sources/drivers.
\end{description}
As mentioned in \cref{subsect:limitations}, only \textbf{many-to-many} approaches
are presented in this paper because they are more generic than \textbf{one-to-one} or
\textbf{many-to-one}.

\subsection{Ethical Challenges}
The importance of \textit{DeepFake} detection increases in conjunction with the
ethical challenges which arise from the use of this technology. The ability to
create arbitrary fake images bears multiple risks for misuse. Firstly, there is
the aspect of misinformation and propaganda. For example by showing images or
videos of political candidates saying things they have not said and that can
incriminate them. Moreover, another aspect to take into consideration would be
pornography, since it is possible to change faces to other people's bodies,
which can lead to non-consensual pornography. Following these dimensions, there
are two types of attacks: to public or political figures and to private
individuals. The first category is defined by attackers having more resources at
hand for an attack, e.g.\ an organized action against a specific political
candidate. The second category, in contrast, is defined by the attackers' lack
of adequate resources, e.g.\ an angry ex-boyfriend. Even though the second
category might pose a real risk since not that much effort might be needed to
spread a basic amount of false information, in the end, the attacker's
capabilities are somewhat limited. However, changes in the ease of use and
availability of \textit{DeepFake} technologies can affect its uses towards
targeting private individuals.