\section{Detection of DeepFakes}\label{sect:detection}
The methods of detecting \textit{DeepFakes} usually do not inhibit major differences
between cases like face swapping or face reenactment.
Instead, they focus on more general concepts like artifacts which are introduced
while using \glspl{gan} or more general aspects of \textit{DeepFakes}.
The area of \textit{DeepFake} detection can be separated in different approaches.
Hereafter, there will be a broad introduction to each approach with an example; however, there
are many more different shapes of these approaches.

\subsection{Physical Approach}
A human on average blinks every two to ten seconds with a duration of \(0.1-0.4\)
seconds~\cite{li_ictu_2018}. Based on this, spontaneous eye blinking would be
expected in \textit{DeepFake} videos. This, however, is not always the case. An
explanation for this circumstance lies in the training data for \glspl{gan}. As 
\textcite{li_ictu_2018} describe, with an exposure time of \(1/30\) of a second,
the likelihood of being captured on a picture while blinking is around \(7.5\%\)~\cite{li_ictu_2018}.
In combination with the fact that most people might prefer pictures of them when
they do not blink online, is commonly thought to be one of the major reasons for
this discrepancy~\cite{pishori_detecting_2020}. Based on this observation, measuring the frequency of blinking can serve as a method of detection of
\textit{DeepFake} videos.

\par
In order to determine the state of the eye, it its necessary to first determine
where the eye is located. This is done in the preprocessing-phase. Here, the facial
landmarks of the pictures are extracted from each face area~\cite{li_ictu_2018}.
To deal with changes in the orientation of the face, there is first an alignment
of the face in a unified coordinate space which moves the face towards the center of the image~\cite{li_ictu_2018}, provided it is not already centered.

\par
The next step is the prediction of the eye's new state. For this, a \gls{lrcn}~\cite{donahue_long-term_2014}
is used. This is because the blinking of human eyes displays strong dependencies to
previous and next images. The \gls{lrcn}-model enables capturing this by using
a combination of \glspl{cnn} and \glspl{lstm}~\cite{donahue_long-term_2014}.
The \gls{cnn} is responsible for the feature detection, in this case the eye
region, into discriminative features~\cite{li_ictu_2018,donahue_long-term_2014}. 
These are fed into the sequence learning which is implemented as a \gls{lstm}.
This enables considering information from previous eye states. The result of
this step is then passed to another \gls{nn} containing a fully connected layer
which has generated the probability of an eye being closed or open~\cite{li_ictu_2018}.

\par
This is only an example of using physical human characteristics to determine a
video or pictures' authenticity. \textcite{li_ictu_2018} describe in 
their paper critically how this might be circumvented by improving the \textit{DeepFake}
generation models to also incorporate eye blinking. Here there are possibilities
to 
\begin{enumerate*}[a.)]
    \item also check for frequency of blinking~\cite{li_ictu_2018} or
    \item change to completely different approaches also used in medicine for
    checking skin color to check for heart rate or similar aspects~\cite{pishori_detecting_2020}.
\end{enumerate*}

\subsection{Artifact-Based Approach}
The algorithms for creating \textit{DeepFakes} might introduce artifacts in the resulting
images. These artifacts can be used to discover \textit{DeepFakes} and lay the foundation
for this type of detection.

\par
\textcite{amerini_deepfake_2019} describe one of these approaches utilizing optical
flow between different frames.
Optical flow, also called motion estimation, aims at the discovery of motion
between an observed object and the observer in two consecutive frames~\cite{beauchemin_computation_1995}.
This is used to find discrepancies between real images and \textit{DeepFakes} in regard
to the movement of the face~\cite{amerini_deepfake_2019}.
\textcite{amerini_deepfake_2019} tested their models on the FaceForensics++ data
with a resulting accuracy of \(81.61\%\).~\textcite{li_celeb-df_2019} found that
on this data set also had the comparatively highest \gls{auc} of \(82.3\%\).
This hints to the model not being that successful, verifying its performance on
a more challenging data set like CELEB-DF~\cite{li_celeb-df_2019} poses
an interesting direction for future research.

\par
Another approach which showed in~\cite{li_celeb-df_2019} the overall highest
average \gls{auc} was \gls{dsp-fwa}, which was introduced by~\cite{he_spatial_2014}
and focuses on discovering face warping artifacts which are introduced by the 
resizing operations in \textit{DeepFake} creation algorithms~\cite{li_celeb-df_2019,he_spatial_2014}.

\par
Similar to the physical approach, this one also requires constant adaptation to
improvements in the generative models which only need to improve to incorporate
dealing with the artifacts which are used for \textit{DeepFake} detection\cite{Mirsky.2020}.

\subsection{Undirected Approaches}
In these approaches, the focus is not on the artifacts, but on training generic
\glspl{nn}, which can select relevant features, informing about whether or not
an image is fake.
\textcite{xuan_generalization_2019} introduced blur and noise to the training phase
to force their model to focus on more intrinsic aspects which in turn should improve
the generalization abilities.
This is contrary to other approaches which focus on e.g.\ pixel density as
described by \textcite{Mirsky.2020}.
