\section{Detection of DeepFakes}
We will focus on the detection of DeepFakes, even though there is also some research in the area of
prevention.

\subsection{Physical Approach}
A human on average blinks every two to ten seconds with a duration of 0.1 to 0.4 seconds~\cite{li_ictu_2018}.
Based on this spontaneous eye blinking would be expected in DeepFake videos.
This however is not always the case.
An exmplanation for this circumstance lies in the training data for GANs.
As \textcite{li_ictu_2018} describe, with an exposure time of 1/30 of a second,
the likelyhood of being captured on a picture while blinking is around 7.5\%~\cite{li_ictu_2018}.
In combination with the fact that most people might prefer pictures of them when they do not blink online,
is commonly thought to be one of the major reasons for this discrepancy~\cite{pishori_detecting_2020}.
Based on this oberservation, the frequency of blinking can be measured and result in a likelyhood of
a video being a DeepFake.

Central for this process is a preprocessing phase which includes the detection of eyes and blinking.


\todo{In Ictu Oculi: Exposing AI Created Fake Videos by Detecting Eye Blinking}

\subsection{Artifact-Based Approach}
The algorithms for creating DeepFakes might introduce artifacts in the resulting images.
These artifacts can be used to discover DeepFakes and lay the foundation for this type of detection.
\todo{Deepfake Video Detection throughOptical Flow Based CNN}

\subsection{Undirected Approaches}
In this approach, the focus is not on the artifacts, but on training gerneric neural networks, which can decide by themself on relevant
features which inform about whether or not an image is fake.
\todo{owards open-set identity preserving facesynthesis}

\subsection{Research Challenges}
When researching DeepFake detection, there is the challenge of having high quality data sets to train and test models on~\cite{li_celeb-df_2019}.
