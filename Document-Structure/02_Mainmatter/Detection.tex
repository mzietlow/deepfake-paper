\section{Detection of DeepFakes}
We will focus on the detection of DeepFakes, even though there is also some 
research in the area of prevention.

\subsection{Physical Approach}
A human on average blinks every two to ten seconds with a duration of \(0.1-0.4\)
seconds~\cite{li_ictu_2018}. Based on this spontaneous eye blinking would be
expected in DeepFake videos. This however is not always the case. An explanation
for this circumstance lies in the training data for \glspl{gan}. As 
\textcite{li_ictu_2018} describe, with an exposure time of \(1/30\) of a second,
the likelihood of being captured on a picture while blinking is around \(7.5\%\)
~\cite{li_ictu_2018}. In combination with the fact that most people might prefer
pictures of them when they do not blink online, is commonly thought to be one of
the major reasons for this discrepancy~\cite{pishori_detecting_2020}. Based on
this observation, the frequency of blinking can be measured and result in a 
likelihood of a video being a DeepFake.

\par
In order for the determine the state of an eye, it its necessary to first determine
where the eye is located. This is done in the preprocessing-phase. Here the facial
landmarks of the pictures are extracted from each face area~\cite{li_ictu_2018}.
To deal with changes in the orientation of the face, there is first an alignment
of the face in a unified coordinate space which, provided it is not already,
move the face to the center of the image~\cite{li_ictu_2018}.

\par
The next aspect is the prediction of an eyes new state, for this a \gls{lrcn}
~\cite{donahue_long-term_2014} is used. This is because blinking of human eyes
displays strong dependencies to previous and next images. The \gls{lrcn}-model 
enables capturing this by utilizing a combination of \glspl{cnn} and \glspl{lstm}
~\cite{donahue_long-term_2014}. The \gls{cnn} is responsible for the feature
detection, in this case the eye region into discriminative features
~\cite{li_ictu_2018,donahue_long-term_2014}. 
These are fed into the sequence learning which is implemented as a \gls{rnn} 
with a \gls{lstm}. This enables considering information from previous eye states.
The result of this step is then passed to another \gls{nn} containing a fully
connected layer which generated the probability of an eye being closed or open~\cite{li_ictu_2018}.

\par
This is only an example of using physical human characteristics to determine a
videos or pictures authenticity. \textcite{li_ictu_2018} describe in 
their paper critically how this might be circumvented by improving the DeepFake
generation models to also incorporate eye blinking. Here there are possibilities
to on the one hand also check for frequency of blinking~\cite{li_ictu_2018} or 
change to completely different approaches also used in medicine of checking skin
color to check for heart rate or similar aspects~\cite{pishori_detecting_2020}.

\todo{In Ictu Oculi: Exposing AI Created Fake Videos by Detecting Eye Blinking}

\subsection{Artifact-Based Approach}
The algorithms for creating DeepFakes might introduce artifacts in the resulting
images. These artifacts can be used to discover DeepFakes and lay the foundation for
this type of detection.
\todo{Deepfake Video Detection through Optical Flow Based CNN}

\subsection{Undirected Approaches}
In this approach, the focus is not on the artifacts, but on training generic
\glspl{nn}, which can select relevant features, informing about whether or not
an image is fake. \todo{owards open-set identity preserving facesynthesis}

\subsection{Research Challenges}
When researching DeepFake detection, there is the challenge of having high
quality data sets to train and test models on~\cite{li_celeb-df_2019}.
